"""
PÃ¡gina de qualidade e limpeza de dados
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import sys

# Adicionar diretÃ³rios ao path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from dataops.clean import DataCleaner, apply_ai_normalization
from ai.ai_assistant import WeibullAIAssistant
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="Qualidade dos Dados - Weibull Fleet Analytics",
    page_icon="ğŸ§¼",
    layout="wide"
)

st.markdown("# ğŸ§¼ Qualidade dos Dados")
st.markdown("AnÃ¡lise e limpeza assistida por IA para garantir dados de alta qualidade")

def create_data_quality_dashboard(df, quality_report):
    """Criar dashboard de qualidade dos dados"""
    
    col1, col2, col3, col4 = st.columns(4)
    
    # Score geral
    score = quality_report['quality_score']
    score_color = "ğŸŸ¢" if score >= 0.8 else "ğŸŸ¡" if score >= 0.6 else "ğŸ”´"
    
    with col1:
        st.metric(
            f"{score_color} Score de Qualidade",
            f"{score:.1%}",
            delta=f"{'Excelente' if score >= 0.8 else 'Bom' if score >= 0.6 else 'Precisa Melhorar'}"
        )
    
    with col2:
        total_missing = sum(quality_report['missing_data'].values())
        st.metric(
            "ğŸ“Š Dados Faltantes",
            f"{total_missing}",
            delta=f"{total_missing/len(df)*100:.1f}% do total"
        )
    
    with col3:
        total_outliers = sum(quality_report['outliers'].values())
        st.metric(
            "ğŸ¯ Outliers Detectados",
            f"{total_outliers}",
            delta=f"{total_outliers/len(df)*100:.1f}% do total"
        )
    
    with col4:
        date_issues = sum(quality_report['date_issues'].values())
        st.metric(
            "ğŸ“… Problemas de Data",
            f"{date_issues}",
            delta=f"{'OK' if date_issues == 0 else 'Verificar'}"
        )

def create_missing_data_chart(quality_report):
    """Criar grÃ¡fico de dados faltantes"""
    missing_data = quality_report['missing_data']
    
    if sum(missing_data.values()) > 0:
        missing_df = pd.DataFrame(list(missing_data.items()), columns=['Coluna', 'Percentual'])
        missing_df = missing_df[missing_df['Percentual'] > 0].sort_values('Percentual', ascending=True)
        
        if len(missing_df) > 0:
            fig = px.bar(
                missing_df,
                x='Percentual',
                y='Coluna',
                orientation='h',
                title='Dados Faltantes por Coluna (%)',
                color='Percentual',
                color_continuous_scale=['green', 'yellow', 'red']
            )
            fig.update_layout(height=300, template='plotly_white')
            return fig
    
    return None

def create_outliers_chart(df, outlier_columns):
    """Criar grÃ¡fico de outliers"""
    if not outlier_columns:
        return None
    
    # Selecionar coluna com mais outliers
    selected_col = outlier_columns[0]
    
    fig = px.box(
        df,
        y=selected_col,
        title=f'DistribuiÃ§Ã£o e Outliers - {selected_col}',
        points='outliers'
    )
    fig.update_layout(template='plotly_white')
    return fig

def analyze_component_names(df):
    """Analisar consistÃªncia de nomes de componentes"""
    if 'component' not in df.columns:
        return None
    
    component_counts = df['component'].value_counts()
    
    # Detectar possÃ­veis duplicatas
    component_names = component_counts.index.tolist()
    potential_duplicates = []
    
    for i, name1 in enumerate(component_names):
        for name2 in component_names[i+1:]:
            # Similaridade simples baseada em palavras comuns
            words1 = set(name1.lower().split())
            words2 = set(name2.lower().split())
            
            if words1 & words2:  # Se hÃ¡ palavras em comum
                potential_duplicates.append((name1, name2))
    
    return component_counts, potential_duplicates

def main():
    # Verificar se hÃ¡ dados carregados
    if 'dataset' not in st.session_state or st.session_state.dataset is None:
        st.warning("ğŸ“¥ Carregue os dados primeiro na pÃ¡gina 'ğŸ—‚ï¸ Dados'")
        return
    
    df = st.session_state.dataset.copy()
    
    # Sidebar com configuraÃ§Ãµes
    with st.sidebar:
        st.markdown("## ğŸ›ï¸ ConfiguraÃ§Ãµes de Limpeza")
        
        auto_clean = st.checkbox("Limpeza AutomÃ¡tica", True)
        normalize_names = st.checkbox("Normalizar Nomes", True)
        remove_outliers = st.checkbox("Remover Outliers", False)
        fill_missing = st.checkbox("Preencher Faltantes", True)
        
        st.markdown("---")
        st.markdown("## ğŸ¤– IA Assistiva")
        
        use_ai_cleaning = st.checkbox("Usar IA para Limpeza", True)
        ai_confidence_threshold = st.slider("ConfianÃ§a MÃ­nima IA", 0.5, 1.0, 0.8)
        
        st.markdown("---")
        st.markdown("## ğŸ“Š Filtros de Qualidade")
        
        min_operating_hours = st.number_input("Horas MÃ­nimas", 0, 1000, 1)
        max_operating_hours = st.number_input("Horas MÃ¡ximas", 1000, 50000, 30000)
    
    # Tabs principais
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š AnÃ¡lise de Qualidade", "ğŸ§¼ Limpeza", "ğŸ¤– IA Assistida", "âœ… ValidaÃ§Ã£o"])
    
    with tab1:
        st.markdown("## ğŸ“Š AnÃ¡lise de Qualidade dos Dados")
        
        if st.button("ğŸ” Executar AnÃ¡lise de Qualidade", type="primary"):
            with st.spinner("Analisando qualidade dos dados..."):
                cleaner = DataCleaner()
                quality_report = cleaner.validate_data_quality(df)
                st.session_state.quality_report = quality_report
                
                st.success("âœ… AnÃ¡lise de qualidade concluÃ­da!")
        
        # Exibir relatÃ³rio se disponÃ­vel
        if 'quality_report' in st.session_state:
            quality_report = st.session_state.quality_report
            
            # Dashboard geral
            create_data_quality_dashboard(df, quality_report)
            
            st.markdown("---")
            
            # GrÃ¡ficos detalhados
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### ğŸ“Š Dados Faltantes")
                fig_missing = create_missing_data_chart(quality_report)
                if fig_missing:
                    st.plotly_chart(fig_missing, use_container_width=True)
                else:
                    st.success("âœ… Nenhum dado faltante encontrado!")
            
            with col2:
                st.markdown("### ğŸ¯ Outliers")
                outlier_cols = [col for col, count in quality_report['outliers'].items() if count > 0]
                if outlier_cols:
                    fig_outliers = create_outliers_chart(df, outlier_cols)
                    if fig_outliers:
                        st.plotly_chart(fig_outliers, use_container_width=True)
                else:
                    st.success("âœ… Nenhum outlier detectado!")
            
            # AnÃ¡lise de consistÃªncia
            st.markdown("### ğŸ” AnÃ¡lise de ConsistÃªncia")
            
            if 'component' in df.columns:
                component_analysis = analyze_component_names(df)
                if component_analysis:
                    component_counts, potential_duplicates = component_analysis
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**Top 10 Componentes:**")
                        st.dataframe(component_counts.head(10))
                    
                    with col2:
                        if potential_duplicates:
                            st.markdown("**âš ï¸ PossÃ­veis Duplicatas:**")
                            for name1, name2 in potential_duplicates[:5]:
                                st.warning(f"â€¢ '{name1}' â†” '{name2}'")
                        else:
                            st.success("âœ… Nenhuma duplicata Ã³bvia encontrada")
    
    with tab2:
        st.markdown("## ğŸ§¼ Limpeza AutomÃ¡tica dos Dados")
        
        if st.button("ğŸ› ï¸ Executar Limpeza Completa", type="primary"):
            with st.spinner("Executando pipeline de limpeza..."):
                cleaner = DataCleaner()
                
                # Pipeline de limpeza
                df_clean, cleaning_summary = cleaner.full_cleaning_pipeline(df)
                
                # Salvar no session state
                st.session_state.dataset_clean = df_clean
                st.session_state.cleaning_summary = cleaning_summary
                
                st.success("âœ… Limpeza concluÃ­da!")
        
        # Exibir resultados da limpeza
        if 'cleaning_summary' in st.session_state:
            summary = st.session_state.cleaning_summary
            
            st.markdown("### ğŸ“‹ Resumo da Limpeza")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "Registros Originais",
                    f"{summary['original_records']:,}",
                )
            
            with col2:
                st.metric(
                    "Registros Limpos",
                    f"{summary['cleaned_records']:,}",
                    delta=f"-{summary['records_removed']}"
                )
            
            with col3:
                quality_score = summary['quality_report']['quality_score']
                st.metric(
                    "Score de Qualidade",
                    f"{quality_score:.1%}",
                    delta=f"{'ğŸŸ¢ Bom' if quality_score >= 0.8 else 'ğŸŸ¡ OK' if quality_score >= 0.6 else 'ğŸ”´ Melhorar'}"
                )
            
            # Detalhes das operaÃ§Ãµes
            st.markdown("### ğŸ”§ OperaÃ§Ãµes Realizadas")
            
            operations = [
                "âœ… PadronizaÃ§Ã£o de colunas",
                "âœ… CorreÃ§Ã£o de unidades",
                "âœ… NormalizaÃ§Ã£o de nomes",
                "âœ… RemoÃ§Ã£o de duplicatas",
                "âœ… InferÃªncia de censura",
                "âœ… DetecÃ§Ã£o de outliers"
            ]
            
            for op in operations:
                st.success(op)
            
            # ComparaÃ§Ã£o antes/depois
            if 'dataset_clean' in st.session_state:
                st.markdown("### ğŸ“Š ComparaÃ§Ã£o Antes/Depois")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**Dados Originais:**")
                    st.dataframe(df.head(5))
                
                with col2:
                    st.markdown("**Dados Limpos:**")
                    st.dataframe(st.session_state.dataset_clean.head(5))
    
    with tab3:
        st.markdown("## ğŸ¤– Limpeza Assistida por IA")
        
        if use_ai_cleaning:
            if st.button("ğŸ§  Executar Limpeza com IA", type="primary"):
                with st.spinner("IA analisando e limpando dados..."):
                    try:
                        ai_assistant = WeibullAIAssistant()
                        
                        # Sugerir limpeza
                        cleaning_suggestion = ai_assistant.suggest_data_cleaning(df)
                        
                        if cleaning_suggestion.success:
                            st.markdown("### ğŸ¤– AnÃ¡lise da IA")
                            st.markdown(cleaning_suggestion.content)
                            
                            if cleaning_suggestion.suggestions:
                                st.markdown("### ğŸ’¡ SugestÃµes da IA")
                                for suggestion in cleaning_suggestion.suggestions:
                                    st.info(f"ğŸ’¡ {suggestion}")
                            
                            # Aplicar normalizaÃ§Ã£o
                            if normalize_names:
                                df_normalized = apply_ai_normalization(
                                    df, 
                                    columns=['component', 'fleet'] if 'fleet' in df.columns else ['component']
                                )
                                
                                st.session_state.dataset_ai_clean = df_normalized
                                
                                st.success("âœ… NormalizaÃ§Ã£o IA aplicada!")
                        
                        else:
                            st.error(f"âŒ Erro na anÃ¡lise IA: {cleaning_suggestion.content}")
                    
                    except Exception as e:
                        st.error(f"âŒ Erro ao chamar IA: {str(e)}")
                        
                        # Fallback para limpeza baseada em regras
                        st.info("ğŸ”„ Executando limpeza baseada em regras como fallback...")
                        
                        cleaner = DataCleaner()
                        df_normalized = apply_ai_normalization(df)
                        st.session_state.dataset_ai_clean = df_normalized
                        
                        st.success("âœ… Limpeza alternativa aplicada!")
            
            # Exibir resultados da IA
            if 'dataset_ai_clean' in st.session_state:
                st.markdown("### ğŸ“Š Resultados da NormalizaÃ§Ã£o IA")
                
                df_ai = st.session_state.dataset_ai_clean
                
                # Comparar nomes antes/depois
                if 'component' in df.columns:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**Componentes Originais:**")
                        original_components = df['component'].value_counts().head(10)
                        st.dataframe(original_components)
                    
                    with col2:
                        st.markdown("**Componentes Normalizados:**")
                        normalized_components = df_ai['component'].value_counts().head(10)
                        st.dataframe(normalized_components)
                
                # EstatÃ­sticas de normalizaÃ§Ã£o
                if 'component_original' in df_ai.columns:
                    changes = (df_ai['component'] != df_ai['component_original']).sum()
                    st.metric(
                        "Componentes Normalizados",
                        changes,
                        delta=f"{changes/len(df_ai)*100:.1f}% do total"
                    )
        
        else:
            st.info("ğŸ¤– Habilite 'Usar IA para Limpeza' no sidebar para usar esta funcionalidade")
    
    with tab4:
        st.markdown("## âœ… ValidaÃ§Ã£o Final")
        
        # Selecionar dataset final
        dataset_options = {
            "Original": df,
        }
        
        if 'dataset_clean' in st.session_state:
            dataset_options["Limpo (AutomÃ¡tico)"] = st.session_state.dataset_clean
        
        if 'dataset_ai_clean' in st.session_state:
            dataset_options["Limpo (IA)"] = st.session_state.dataset_ai_clean
        
        selected_dataset = st.selectbox(
            "Selecionar Dataset Final:",
            list(dataset_options.keys())
        )
        
        final_df = dataset_options[selected_dataset]
        
        if st.button("ğŸ” Validar Dataset Final", type="primary"):
            with st.spinner("Validando dataset final..."):
                cleaner = DataCleaner()
                final_quality = cleaner.validate_data_quality(final_df)
                
                # Dashboard final
                st.markdown("### ğŸ“Š Qualidade Final")
                create_data_quality_dashboard(final_df, final_quality)
                
                # RecomendaÃ§Ã£o
                score = final_quality['quality_score']
                if score >= 0.8:
                    st.success("ğŸ‰ Dataset estÃ¡ pronto para anÃ¡lise Weibull!")
                elif score >= 0.6:
                    st.warning("âš ï¸ Dataset tem qualidade razoÃ¡vel, mas pode ser melhorado")
                else:
                    st.error("âŒ Dataset precisa de mais limpeza antes da anÃ¡lise")
        
        # BotÃµes de aÃ§Ã£o
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ’¾ Salvar Dataset Final"):
                st.session_state.dataset = final_df
                st.success("âœ… Dataset salvo como versÃ£o principal!")
        
        with col2:
            if st.button("ğŸ“¥ Download Dataset"):
                csv = final_df.to_csv(index=False).encode('utf-8')
                
                st.download_button(
                    label="ğŸ“¥ Download CSV Limpo",
                    data=csv,
                    file_name=f'dataset_limpo_{selected_dataset.lower()}.csv',
                    mime='text/csv'
                )
        
        with col3:
            if st.button("â¡ï¸ PrÃ³xima Etapa"):
                st.info("Navigate to 'ğŸ“ˆ Ajuste Weibull' para anÃ¡lise")

if __name__ == "__main__":
    main()